{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b4b7c7",
   "metadata": {},
   "source": [
    "# DeepFake CNN Classifier\n",
    "This notebook trains a deepfake image classifier using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33fa038",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a704c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b11fbc",
   "metadata": {},
   "source": [
    "## Set Random Seed and Define Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52aa293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d7b72",
   "metadata": {},
   "source": [
    "## Define Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a76d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_DIR = \"wiki\"\n",
    "FAKE_DIRS = [\"inpainting\", \"insight\", \"text2img\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadf2d0",
   "metadata": {},
   "source": [
    "## Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932ec6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFakeDataset(Dataset):\n",
    "    def __init__(self, real_dir, fake_dirs, split='train', transform=None, val_split=0.15, test_split=0.15, max_images_per_class=None):\n",
    "        \"\"\"\n",
    "        Dataset for loading DeepFake Face images.\n",
    "\n",
    "        Args:\n",
    "            real_dir: Directory containing real images\n",
    "            fake_dirs: List of directories containing fake images\n",
    "            split: One of 'train', 'val', or 'test'\n",
    "            transform: Image transformations\n",
    "            val_split: Proportion of data for validation\n",
    "            test_split: Proportion of data for testing\n",
    "            max_images_per_class: Maximum number of images to use per class (real/fake)\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get all image paths with limit\n",
    "        real_images = self._get_image_paths(real_dir, label=0, max_images=max_images_per_class)  # 0 = real\n",
    "\n",
    "        fake_images = []\n",
    "        # If we have multiple fake directories, distribute the limit among them\n",
    "        fake_dir_limit = None\n",
    "        if max_images_per_class is not None:\n",
    "            fake_dir_limit = max_images_per_class // len(fake_dirs)\n",
    "\n",
    "        for fake_dir in fake_dirs:\n",
    "            fake_images.extend(self._get_image_paths(fake_dir, label=1, max_images=fake_dir_limit))  # 1 = fake\n",
    "\n",
    "        # Combine and shuffle\n",
    "        all_images = real_images + fake_images\n",
    "        np.random.shuffle(all_images)\n",
    "\n",
    "        # Print dataset stats\n",
    "        print(f\"Loaded {len(real_images)} real images and {len(fake_images)} fake images\")\n",
    "\n",
    "        # Split into train, val, test\n",
    "        total_size = len(all_images)\n",
    "        test_size = int(total_size * test_split)\n",
    "        val_size = int(total_size * val_split)\n",
    "        train_size = total_size - test_size - val_size\n",
    "\n",
    "        if split == 'train':\n",
    "            self.images = all_images[:train_size]\n",
    "        elif split == 'val':\n",
    "            self.images = all_images[train_size:train_size+val_size]\n",
    "        elif split == 'test':\n",
    "            self.images = all_images[train_size+val_size:]\n",
    "        else:\n",
    "            raise ValueError(\"Split must be one of 'train', 'val', or 'test'\")\n",
    "\n",
    "        print(f\"{split} dataset size: {len(self.images)}\")\n",
    "    \n",
    "    def _get_image_paths(self, directory, label, max_images=None):\n",
    "        \"\"\"Get all image paths with labels from directory with an optional limit\"\"\"\n",
    "        image_paths = []\n",
    "\n",
    "        # Recursively walk through directory structure\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_paths.append((os.path.join(root, file), label))\n",
    "                    # Check if we've reached the limit\n",
    "                    if max_images is not None and len(image_paths) >= max_images:\n",
    "                        return image_paths\n",
    "\n",
    "        return image_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        \n",
    "        # Load and convert image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a placeholder in case of error\n",
    "            if self.transform:\n",
    "                return torch.zeros((3, 224, 224)), label\n",
    "            return torch.zeros((3, 224, 224)), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58cb482",
   "metadata": {},
   "source": [
    "## Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1efc947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFakeClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(DeepFakeClassifier, self).__init__()\n",
    "        \n",
    "        # Use a pre-trained ResNet as base model\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Replace final fully connected layer\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858e386",
   "metadata": {},
   "source": [
    "## Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298c65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    model.to(device)\n",
    "    best_val_accuracy = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_all_preds = []\n",
    "        val_all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_all_preds.extend(preds.cpu().numpy())\n",
    "                val_all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_epoch_acc = accuracy_score(val_all_labels, val_all_preds)\n",
    "        \n",
    "        history['val_loss'].append(val_epoch_loss)\n",
    "        history['val_acc'].append(val_epoch_acc)\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(val_epoch_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_epoch_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_epoch_acc\n",
    "            torch.save(model.state_dict(), 'best_deepfake_classifier.pth')\n",
    "            print(f\"Saved best model with validation accuracy: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a4734",
   "metadata": {},
   "source": [
    "# Evaluation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da8793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Real', 'Fake'], \n",
    "                yticklabels=['Real', 'Fake'])\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot ROC curve for binary classification\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Plot training history\n",
    "    def plot_history(history):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['train_loss'], label='Training Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Loss over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "        plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "        plt.title('Accuracy over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'predictions': all_preds,\n",
    "        'true_labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6638279c",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c673d7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30000 real images and 90000 fake images\n",
      "train dataset size: 108000\n",
      "Loaded 30000 real images and 90000 fake images\n",
      "val dataset size: 6000\n",
      "Testing a single batch processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\trabalho_labsiacd\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\envs\\trabalho_labsiacd\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch: images shape torch.Size([4, 3, 224, 224]), labels shape torch.Size([4])\n",
      "Forward pass successful, loss: 0.6693949699401855\n",
      "Debug complete!\n"
     ]
    }
   ],
   "source": [
    "def debug_main():\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets (with smaller splits for testing)\n",
    "    train_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='train', transform=transform, \n",
    "                                   val_split=0.05, test_split=0.05)\n",
    "    val_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='val', transform=transform,\n",
    "                                 val_split=0.05, test_split=0.05)\n",
    "    \n",
    "    # Create dataloaders with smaller batch size and fewer workers\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Try to process a single batch to verify everything works\n",
    "    print(\"Testing a single batch processing...\")\n",
    "    model = DeepFakeClassifier(num_classes=2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Try one training iteration\n",
    "    for images, labels in train_loader:\n",
    "        print(f\"Loaded batch: images shape {images.shape}, labels shape {labels.shape}\")\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        print(f\"Forward pass successful, loss: {loss.item()}\")\n",
    "        break\n",
    "    \n",
    "    print(\"Debug complete!\")\n",
    "\n",
    "# Run the debug function\n",
    "debug_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1597e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30000 real images and 90000 fake images\n",
      "train dataset size: 84000\n",
      "Loaded 30000 real images and 90000 fake images\n",
      "val dataset size: 18000\n",
      "Loaded 30000 real images and 90000 fake images\n",
      "test dataset size: 18000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\trabalho_labsiacd\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/15 - Training:   0%|                                                                  | 0/2625 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# este é o main original mas nao consegui corrê-lo porque demorava muito tempo\n",
    "def main():\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='train', transform=transform)\n",
    "    val_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='val', transform=transform)\n",
    "    test_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='test', transform=transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Create model\n",
    "    model = DeepFakeClassifier(num_classes=2)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    \n",
    "    # Train model\n",
    "    model, history = train_model(\n",
    "        model=model, \n",
    "        train_loader=train_loader, \n",
    "        val_loader=val_loader, \n",
    "        criterion=criterion, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler, \n",
    "        num_epochs=15\n",
    "    )\n",
    "    \n",
    "    # Load best model for evaluation\n",
    "    model.load_state_dict(torch.load('best_deepfake_classifier.pth'))\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluation_results = evaluate_model(model, test_loader)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Training and evaluation complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0b1b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 real images and 498 fake images\n",
      "train dataset size: 700\n",
      "Loaded 500 real images and 498 fake images\n",
      "val dataset size: 149\n",
      "Loaded 500 real images and 498 fake images\n",
      "test dataset size: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\trabalho_labsiacd\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1/5 - Training: 100%|████████████████████████████████████████████████████████████| 88/88 [05:40<00:00,  3.87s/it]\n",
      "Epoch 1/5 - Validation: 100%|██████████████████████████████████████████████████████████| 19/19 [00:22<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 0.8338, Train Acc: 0.5000, Val Loss: 0.6937, Val Acc: 0.5705\n",
      "Saved best model with validation accuracy: 0.5705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Training: 100%|████████████████████████████████████████████████████████████| 88/88 [05:17<00:00,  3.61s/it]\n",
      "Epoch 2/5 - Validation: 100%|██████████████████████████████████████████████████████████| 19/19 [00:20<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 0.7088, Train Acc: 0.4686, Val Loss: 0.6928, Val Acc: 0.5101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Training: 100%|████████████████████████████████████████████████████████████| 88/88 [05:16<00:00,  3.60s/it]\n",
      "Epoch 3/5 - Validation: 100%|██████████████████████████████████████████████████████████| 19/19 [00:20<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.7027, Train Acc: 0.5100, Val Loss: 0.7149, Val Acc: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Training: 100%|████████████████████████████████████████████████████████████| 88/88 [05:14<00:00,  3.57s/it]\n",
      "Epoch 4/5 - Validation: 100%|██████████████████████████████████████████████████████████| 19/19 [00:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.7004, Train Acc: 0.5086, Val Loss: 0.6947, Val Acc: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Training: 100%|████████████████████████████████████████████████████████████| 88/88 [05:14<00:00,  3.57s/it]\n",
      "Epoch 5/5 - Validation: 100%|██████████████████████████████████████████████████████████| 19/19 [00:20<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.6987, Train Acc: 0.4914, Val Loss: 0.7200, Val Acc: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████| 19/19 [00:21<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5369\n",
      "Precision: 0.5373\n",
      "Recall: 0.5369\n",
      "F1 Score: 0.5341\n",
      "Training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Set a limit for the number of images per class\n",
    "    max_images_per_class = 500  # You can adjust this number\n",
    "    \n",
    "    # Create datasets with limited images\n",
    "    train_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='train', transform=transform, max_images_per_class=max_images_per_class)\n",
    "    val_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='val', transform=transform, max_images_per_class=max_images_per_class)\n",
    "    test_dataset = DeepFakeDataset(REAL_DIR, FAKE_DIRS, split='test', transform=transform, max_images_per_class=max_images_per_class)\n",
    "    \n",
    "    # Create dataloaders with smaller batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Create model\n",
    "    model = DeepFakeClassifier(num_classes=2)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    \n",
    "    # Train model with fewer epochs\n",
    "    model, history = train_model(\n",
    "        model=model, \n",
    "        train_loader=train_loader, \n",
    "        val_loader=val_loader, \n",
    "        criterion=criterion, \n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler, \n",
    "        num_epochs=5  # Reduced epochs for faster training\n",
    "    )\n",
    "    \n",
    "    # Load best model for evaluation\n",
    "    model.load_state_dict(torch.load('best_deepfake_classifier.pth'))\n",
    "    \n",
    "    # Evaluate model\n",
    "    evaluation_results = evaluate_model(model, test_loader)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Training and evaluation complete!\")\n",
    "\n",
    "# Run main with limited dataset\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
